<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Team name</title><link>https://ckids-datafest.github.io/2023-fall-software-ecosystems/</link><atom:link href="https://ckids-datafest.github.io/2023-fall-software-ecosystems/index.xml" rel="self" type="application/rss+xml"/><description>Team name</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate><image><url>https://ckids-datafest.github.io/2023-fall-software-ecosystems/media/icon_hu5486d42984c30aaff6be99d37062b147_3155_512x512_fill_lanczos_center_3.png</url><title>Team name</title><link>https://ckids-datafest.github.io/2023-fall-software-ecosystems/</link></image><item><title>People</title><link>https://ckids-datafest.github.io/2023-fall-software-ecosystems/people/</link><pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate><guid>https://ckids-datafest.github.io/2023-fall-software-ecosystems/people/</guid><description/></item><item><title>Approach</title><link>https://ckids-datafest.github.io/2023-fall-software-ecosystems/approach/</link><pubDate>Thu, 28 Jun 2018 00:00:00 +0000</pubDate><guid>https://ckids-datafest.github.io/2023-fall-software-ecosystems/approach/</guid><description>&lt;h2 id="data-preprocessing">Data Preprocessing&lt;/h2>
&lt;p>The raw data follows a format that can be used to parse it and extract clean messages. However, there are still some residues that cannot be removed. We use regular expressions to minimize the amount of residues in the clean messages.&lt;/p>
&lt;h2 id="model-development">Model Development&lt;/h2>
&lt;p>We tried out different large language models to perform keyword extraction and summarization. Several models from &lt;a href="https://huggingface.co/" target="_blank" rel="noopener">Hugging Face&lt;/a> are evaluated. We follow the description of the model on the website to implement them. In addition, we have designed several functions using the OpenAI models and Llama2 through API calls.&lt;/p>
&lt;h2 id="model-evaluation">Model Evaluation&lt;/h2>
&lt;p>We randomly selected 20 messages to evaluate the performance of different large language models. For keyword extraction, we compare model predictions with manually generated results by counting the number of missed and matched keywords. To evaluate the performance of the text summarization, we calculated the number of keywords retained in the summary compared to the original text. For both tasks, we compute the precision, recall, and f1 score of each model and compare their performance.&lt;/p></description></item><item><title>Data Assessment</title><link>https://ckids-datafest.github.io/2023-fall-software-ecosystems/data/</link><pubDate>Thu, 28 Jun 2018 00:00:00 +0000</pubDate><guid>https://ckids-datafest.github.io/2023-fall-software-ecosystems/data/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>Our project uses data from &lt;a href="https://lkml.org/" target="_blank" rel="noopener">Linux Kernel Mailing List&lt;/a>.&lt;/p>
&lt;h2 id="data-overview-and-examples">Data Overview and Examples&lt;/h2>
&lt;p>The data contains technical discussions on the design of and bugs in the Linux kernel. It is collected with a Python script and serves as our data source to develop our project. As of now, only a small portion of the data has been used to debug and evaluate our code. However, we might analyze all the available data from the mailing list in future works.&lt;/p>
&lt;h2 id="data-accessibility">Data Accessibility&lt;/h2>
&lt;p>The data is public on &lt;a href="https://lkml.org/" target="_blank" rel="noopener">LKML.ORG&lt;/a>. You can access the archived messages directly from the website.&lt;/p>
&lt;h2 id="data-formats-and-challenges">Data Formats and Challenges&lt;/h2>
&lt;p>The data is in email format which contains the time stamp, author&amp;rsquo;s information, subject and content of the email. It contains both source codes and commit messages. Since the data contains some useless texts, we need to extract the clean messages. We use certain symbols as delimiters and leverage the power of regular expression to implement a parser for the raw data.&lt;/p></description></item><item><title>Problem and Requirements</title><link>https://ckids-datafest.github.io/2023-fall-software-ecosystems/problem-statement/</link><pubDate>Thu, 28 Jun 2018 00:00:00 +0000</pubDate><guid>https://ckids-datafest.github.io/2023-fall-software-ecosystems/problem-statement/</guid><description>&lt;h2 id="motivation-and-goal">Motivation and Goal&lt;/h2>
&lt;p>Open source runs a lot of the world&amp;rsquo;s critical software systems, but they suffer from vulnerabilities that can lead to severe damage such as data breach, compromised system, financial loss, etc. Therefore, vulnerability assessment is needed. In addition, there is much that&amp;rsquo;s unknown in how maintainers, developers and other parts of the software ecosystem function.&lt;/p>
&lt;p>This project attempts to analyze code commits of open-source software repositories, that include both source code and patch conversations, to better understand them. We believe our project can help protect the health of OSS code and communities.&lt;/p>
&lt;h2 id="problem-for-the-semester">Problem for the Semester&lt;/h2>
&lt;ul>
&lt;li>Extract clean messages from the raw data from Linux Kernel Mailing List.&lt;/li>
&lt;li>Match each message to its maintainer group.&lt;/li>
&lt;li>Extract keywords from individual messages and patch discussions.&lt;/li>
&lt;li>Generate a summarization from each individual messages and patch discussions.&lt;/li>
&lt;/ul>
&lt;h2 id="state-of-the-art">State of the Art&lt;/h2>
&lt;p>We used certain delimiters and regular expressions to extract clean messages. To accomplish keyword extraction and summarization, we leveraged the power of large language models such as GPT4 and Llama2.&lt;/p>
&lt;h2 id="design-and-approach">Design and Approach&lt;/h2>
&lt;ol>
&lt;li>Write a parser to extract clean messages from the raw data. We use a small portion of the data to debug the parser.&lt;/li>
&lt;li>Try out different large lanugae models on keyword extraction and summarization for a single message and evaluate their performance. For each task, we compare the model predictions with manually generated results and compute the precision, recall and f1 score.&lt;/li>
&lt;li>Construct a pipeline(Python script) that takes in the raw data and outputs the clean messages, and extracted keywords and summarizations for each message.&lt;/li>
&lt;li>Match each message with its maintainer group.&lt;/li>
&lt;li>Implement functions to perform keyword extraction and summarization on a list of messages.&lt;/li>
&lt;/ol>
&lt;h2 id="use-case-scenario">Use Case Scenario&lt;/h2>
&lt;p>Maintainers of open source software can use our project to check for any malicious code submissions in patch discussions.&lt;/p>
&lt;h2 id="desired-outcomes-and-benefits">Desired Outcomes and Benefits&lt;/h2>
&lt;p>Topic modeling: We will analyze the messages under each maintainer group and add labels to each of them. Malicious code commit can become more obvious when it doesn&amp;rsquo;t match with the label of the maintainer group.&lt;/p></description></item><item><title>Results</title><link>https://ckids-datafest.github.io/2023-fall-software-ecosystems/results/</link><pubDate>Thu, 28 Jun 2018 00:00:00 +0000</pubDate><guid>https://ckids-datafest.github.io/2023-fall-software-ecosystems/results/</guid><description>&lt;h2 id="system-and-model-performance">System and Model Performance&lt;/h2>
&lt;div align="center">
&lt;img src="message_extraction.png" />
&lt;p>Clean Message Extraction&lt;/p>
&lt;img src="match_maintainer.png" />
&lt;p>Matching Each Message with Its Maintainer Group&lt;/p>
&lt;img src="time_improvement.png" />
&lt;p>Time Cost&lt;/p>
&lt;img src="keyword_extraction.png" />
&lt;p>Keyword Extraction&lt;/p>
&lt;img src="text_summarization.png" />
&lt;p>Text Summarization&lt;/p>
&lt;/div>
&lt;h2 id="discussion-of-findings">Discussion of Findings&lt;/h2>
&lt;ol>
&lt;li>Message Extraction: After the cleaning process, the message that contains incomplete content is reduced to 1.2%.&lt;/li>
&lt;li>Message Matching: The accuracy of finding the correct matching of the maintainer group is increased by 16%.&lt;/li>
&lt;li>Time Cost: The use of time to match 174242 messages was reduced from 117 minutes to 28 minutes by using a hash table to reduce repeated matching.&lt;/li>
&lt;li>Keyword Extraction: Overall, KeyLLM with GPT4 has the highest performance. An interesting finding is that the models from hugging faces have high precision but low recall. This indicates they are able to recognize desired keywords but are incapable of extracting all of them.&lt;/li>
&lt;li>Text Summarization: According to the results, GPT4 performs the best.&lt;/li>
&lt;/ol>
&lt;h2 id="limitations-and-future-work">Limitations and Future Work&lt;/h2>
&lt;p>The results show that GPT4 has excellent performance on both tasks. We will use it for topic modeling in the future.&lt;/p>
&lt;p>One limitation, however, is the cost of the model. With millions of messages on mailing lists, the cost of analyzing all of them can be huge. An alternative is Llama2, since it has good performance and is free to use.&lt;/p></description></item></channel></rss>