[{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696363238,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://ckids-datafest.github.io/2023-fall-software-ecosystems/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/2023-fall-software-ecosystems/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":null,"categories":null,"content":"Data Preprocessing The raw data follows a format that can be used to parse it and extract clean messages. However, there are still some residues that cannot be removed. We use regular expressions to minimize the amount of residues in the clean messages.\nModel Development We tried out different large language models to perform keyword extraction and summarization. Several models from Hugging Face are evaluated. We follow the description of the model on the website to implement them. In addition, we have designed several functions using the OpenAI models and Llama2 through API calls.\nModel Evaluation We randomly selected 20 messages to evaluate the performance of different large language models. For keyword extraction, we compare model predictions with manually generated results by counting the number of missed and matched keywords. To evaluate the performance of the text summarization, we calculated the number of keywords retained in the summary compared to the original text. For both tasks, we compute the precision, recall, and f1 score of each model and compare their performance.\n","date":1530144e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701418664,"objectID":"3e050718825977bdecb55c075afa314a","permalink":"https://ckids-datafest.github.io/2023-fall-software-ecosystems/approach/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/2023-fall-software-ecosystems/approach/","section":"","summary":"Data science methodology used to address the problem, including data preprocessing steps, exploratory data analysis, feature engineering techniques, machine learning models, and evaluation metrics.","tags":null,"title":"Approach","type":"page"},{"authors":null,"categories":null,"content":"Introduction Our project uses data from Linux Kernel Mailing List.\nData Overview and Examples The data contains technical discussions on the design of and bugs in the Linux kernel. It is collected with a Python script and serves as our data source to develop our project. As of now, only a small portion of the data has been used to debug and evaluate our code. However, we might analyze all the available data from the mailing list in future works.\nData Accessibility The data is public on LKML.ORG. You can access the archived messages directly from the website.\nData Formats and Challenges The data is in email format which contains the time stamp, author’s information, subject and content of the email. It contains both source codes and commit messages. Since the data contains some useless texts, we need to extract the clean messages. We use certain symbols as delimiters and leverage the power of regular expression to implement a parser for the raw data.\n","date":1530144e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701418696,"objectID":"be566fdb6f0fa08cfea50d77a89a6b5a","permalink":"https://ckids-datafest.github.io/2023-fall-software-ecosystems/data/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/2023-fall-software-ecosystems/data/","section":"","summary":"Data Assessment Document that gives an overview of the data used for the project.","tags":null,"title":"Data Assessment","type":"page"},{"authors":null,"categories":null,"content":"Motivation and Goal Open source runs a lot of the world’s critical software systems, but they suffer from vulnerabilities that can lead to severe damage such as data breach, compromised system, financial loss, etc. Therefore, vulnerability assessment is needed. In addition, there is much that’s unknown in how maintainers, developers and other parts of the software ecosystem function.\nThis project attempts to analyze code commits of open-source software repositories, that include both source code and patch conversations, to better understand them. We believe our project can help protect the health of OSS code and communities.\nProblem for the Semester Extract clean messages from the raw data from Linux Kernel Mailing List. Match each message to its maintainer group. Extract keywords from individual messages and patch discussions. Generate a summarization from each individual messages and patch discussions. State of the Art We used certain delimiters and regular expressions to extract clean messages. To accomplish keyword extraction and summarization, we leveraged the power of large language models such as GPT4 and Llama2.\nDesign and Approach Write a parser to extract clean messages from the raw data. We use a small portion of the data to debug the parser. Try out different large lanugae models on keyword extraction and summarization for a single message and evaluate their performance. For each task, we compare the model predictions with manually generated results and compute the precision, recall and f1 score. Construct a pipeline(Python script) that takes in the raw data and outputs the clean messages, and extracted keywords and summarizations for each message. Match each message with its maintainer group. Implement functions to perform keyword extraction and summarization on a list of messages. Use Case Scenario Maintainers of open source software can use our project to check for any malicious code submissions in patch discussions.\nDesired Outcomes and Benefits Topic modeling: We will analyze the messages under each maintainer group and add labels to each of them. Malicious code commit can become more obvious when it doesn’t match with the label of the maintainer group.\n","date":1530144e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701417657,"objectID":"b7c3446bb0d5d7e8a477294017361379","permalink":"https://ckids-datafest.github.io/2023-fall-software-ecosystems/problem-statement/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/2023-fall-software-ecosystems/problem-statement/","section":"","summary":"Problem and Requirements document that will drive the work to be done in the project","tags":null,"title":"Problem and Requirements","type":"page"},{"authors":null,"categories":null,"content":"System and Model Performance Clean Message Extraction\nMatching Each Message with Its Maintainer Group\nTime Cost\nKeyword Extraction\nText Summarization\nDiscussion of Findings Message Extraction: After the cleaning process, the message that contains incomplete content is reduced to 1.2%. Message Matching: The accuracy of finding the correct matching of the maintainer group is increased by 16%. Time Cost: The use of time to match 174242 messages was reduced from 117 minutes to 28 minutes by using a hash table to reduce repeated matching. Keyword Extraction: Overall, KeyLLM with GPT4 has the highest performance. An interesting finding is that the models from hugging faces have high precision but low recall. This indicates they are able to recognize desired keywords but are incapable of extracting all of them. Text Summarization: According to the results, GPT4 performs the best. Limitations and Future Work The results show that GPT4 has excellent performance on both tasks. We will use it for topic modeling in the future.\nOne limitation, however, is the cost of the model. With millions of messages on mailing lists, the cost of analyzing all of them can be huge. An alternative is Llama2, since it has good performance and is free to use.\n","date":1530144e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701418797,"objectID":"c29e41198fe1dc5c85e66dbe4f2d7737","permalink":"https://ckids-datafest.github.io/2023-fall-software-ecosystems/results/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/2023-fall-software-ecosystems/results/","section":"","summary":"The main results of the work done to date","tags":null,"title":"Results","type":"page"}]